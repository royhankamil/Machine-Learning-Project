{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preproccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dalam tahapan ini kita akan melakukan importing untuk library dan dataset yang akan digunakan dalam developing Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-31 14:32:04+00:00</td>\n",
       "      <td>pikobar_jabar</td>\n",
       "      <td>Ketahui informasi pembagian #PPKM di wilayah J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-31 09:26:00+00:00</td>\n",
       "      <td>inewsdotid</td>\n",
       "      <td>Tempat Ibadah di Wilayah PPKM Level 1 Boleh Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-31 05:02:34+00:00</td>\n",
       "      <td>vdvc_talk</td>\n",
       "      <td>Juru bicara Satgas Covid-19, Wiku Adisasmito m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-30 14:23:10+00:00</td>\n",
       "      <td>pikobar_jabar</td>\n",
       "      <td>Ketahui informasi pembagian #PPKM di wilayah J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-30 11:28:57+00:00</td>\n",
       "      <td>tvOneNews</td>\n",
       "      <td>Kementerian Agama menerbitkan Surat Edaran Nom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date           User  \\\n",
       "0  2022-03-31 14:32:04+00:00  pikobar_jabar   \n",
       "1  2022-03-31 09:26:00+00:00     inewsdotid   \n",
       "2  2022-03-31 05:02:34+00:00      vdvc_talk   \n",
       "3  2022-03-30 14:23:10+00:00  pikobar_jabar   \n",
       "4  2022-03-30 11:28:57+00:00      tvOneNews   \n",
       "\n",
       "                                               Tweet  sentiment  \n",
       "0  Ketahui informasi pembagian #PPKM di wilayah J...          1  \n",
       "1  Tempat Ibadah di Wilayah PPKM Level 1 Boleh Be...          1  \n",
       "2  Juru bicara Satgas Covid-19, Wiku Adisasmito m...          1  \n",
       "3  Ketahui informasi pembagian #PPKM di wilayah J...          1  \n",
       "4  Kementerian Agama menerbitkan Surat Edaran Nom...          1  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengambil dataset\n",
    "df = pd.read_csv(\"dataset/INA_TweetsPPKM_Labeled_Pure.csv\", sep=\"\\t\") \n",
    "\n",
    "# menampilkan 10 teratas data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : Positif, 1 : Netral, 2 : Negatif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    17706\n",
       "2     3980\n",
       "0     1958\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melihat berapa banyak tweet positif dan negatif dan netal\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dari di atas, kita bisa melihat bahwa data yang paling banyak adalah data yang netral. Disusul dengan data negatif yang paling banyak tentang tweet ppkm ini. Dan yang paling sedikit adalah tweet yang berisi positif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di dalam tahapan ini kita akan membuang untuk fitur yang tidak akan dipakai. Disini kita memutuskan untuk memakai 2 fitur yaitu Tweet sebagai x dan sentiment sebagai label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menggunakan fitur yang diperlukan saja\n",
    "df = df[[\"Tweet\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk meringankan dan menyeimbangkan data kita perlu mengambil data dengan masing masing label 1900. Mengapa 1900 karena 1900 dapat memuat semua data positif, kalau lebih dari itu, kita tidak bisa menyeimbangkan data positif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Stay safe and healthy gaess! Jangan lupa untuk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10257</td>\n",
       "      <td>Merah Putih Terus Berkibar https://t.co/zAp4RD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1779</td>\n",
       "      <td>LIST 3 FILM TENTANG HUJAN WAJIB TONTON https:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13914</td>\n",
       "      <td>Selalu patuhi anjuran pemerintah dengan tetap ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1312</td>\n",
       "      <td>Tekan Kenaikan Angka COVID-19, #PPKM Mikro Dib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              Tweet  sentiment\n",
       "0    862  Stay safe and healthy gaess! Jangan lupa untuk...          1\n",
       "1  10257  Merah Putih Terus Berkibar https://t.co/zAp4RD...          0\n",
       "2   1779  LIST 3 FILM TENTANG HUJAN WAJIB TONTON https:/...          1\n",
       "3  13914  Selalu patuhi anjuran pemerintah dengan tetap ...          0\n",
       "4   1312  Tekan Kenaikan Angka COVID-19, #PPKM Mikro Dib...          1"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untuk mengambil masing2 label 1900 lalu diacak\n",
    "df = pd.concat([df[df[\"sentiment\"] == 0][:1900], df[df[\"sentiment\"] == 1][:1900], df[df[\"sentiment\"] == 2][:1900]]).sample(frac=1,random_state=123).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6745</td>\n",
       "      <td>hayu pesen jen's snack gais...cemilan enak nih...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5301</td>\n",
       "      <td>Meski #PPKM harus tetap produktiv dong \\n Ini ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6043</td>\n",
       "      <td>Gimana mau bayar pajak bu kita aja di bikin su...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>653</td>\n",
       "      <td>Kota Bandung saat ini PPKM level 3?\\nLalu, bag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7367</td>\n",
       "      <td>Enaknya ngapain yah? #ppkm</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1192</td>\n",
       "      <td>Bagus sekali Jenderal Kalau seperti ini lebih ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12522</td>\n",
       "      <td>Ohhh ternyata yg dilanjut PPKM , hubungan kita...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19945</td>\n",
       "      <td>Nah buat kamu yang mau berkegiatan selama PPKM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7575</td>\n",
       "      <td>🗣: 17 agustus ntar kemana nih? Tempat hiburan/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4814</td>\n",
       "      <td>❕PAMERAN VIRTUAL 360° YANG PALING DITUNGGU ❕ \\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7927</td>\n",
       "      <td>Belum semua orang bisa divaksin. Lalu bagaiman...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2015</td>\n",
       "      <td>Saya menjual [Cairan Khusus] HOCL... seharga R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4085</td>\n",
       "      <td>@detikcom Apakah Janji kampanye pilkada DKI ti...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1606</td>\n",
       "      <td>Salah satu yang menyebabkan pembatalan ini men...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1971</td>\n",
       "      <td>In accordance with the Home Affairs Ministry i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14413</td>\n",
       "      <td>Alhamdulillah cukup lah buat sehari🙏🏻. Terimak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1948</td>\n",
       "      <td>#Live wawancara dengan Epidemiolog Pandu Riono...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>12468</td>\n",
       "      <td>Gmna nasib kami anak rantau\\nPPKM diperpanjang...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12199</td>\n",
       "      <td>Halo Sahabat IDwebhost, PPKM diperpanjang ya? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>950</td>\n",
       "      <td>Kasus kematian pasien COVID-19 terus bertambah...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              Tweet  sentiment\n",
       "30   6745  hayu pesen jen's snack gais...cemilan enak nih...          0\n",
       "31   5301  Meski #PPKM harus tetap produktiv dong \\n Ini ...          0\n",
       "32   6043  Gimana mau bayar pajak bu kita aja di bikin su...          2\n",
       "33    653  Kota Bandung saat ini PPKM level 3?\\nLalu, bag...          1\n",
       "34   7367                         Enaknya ngapain yah? #ppkm          2\n",
       "35   1192  Bagus sekali Jenderal Kalau seperti ini lebih ...          1\n",
       "36  12522  Ohhh ternyata yg dilanjut PPKM , hubungan kita...          2\n",
       "37  19945  Nah buat kamu yang mau berkegiatan selama PPKM...          0\n",
       "38   7575  🗣: 17 agustus ntar kemana nih? Tempat hiburan/...          0\n",
       "39   4814  ❕PAMERAN VIRTUAL 360° YANG PALING DITUNGGU ❕ \\...          0\n",
       "40   7927  Belum semua orang bisa divaksin. Lalu bagaiman...          2\n",
       "41   2015  Saya menjual [Cairan Khusus] HOCL... seharga R...          1\n",
       "42   4085  @detikcom Apakah Janji kampanye pilkada DKI ti...          2\n",
       "43   1606  Salah satu yang menyebabkan pembatalan ini men...          2\n",
       "44   1971  In accordance with the Home Affairs Ministry i...          1\n",
       "45  14413  Alhamdulillah cukup lah buat sehari🙏🏻. Terimak...          0\n",
       "46   1948  #Live wawancara dengan Epidemiolog Pandu Riono...          1\n",
       "47  12468  Gmna nasib kami anak rantau\\nPPKM diperpanjang...          2\n",
       "48  12199  Halo Sahabat IDwebhost, PPKM diperpanjang ya? ...          0\n",
       "49    950  Kasus kematian pasien COVID-19 terus bertambah...          1"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.iloc[31]\n",
    "df.iloc[30:].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "di dalam tahapan ini kita akan memeriksa apakah ada data yang terduplikasi. Jika iya, maka kita perlu memakai salah satu dari duplikasi tersebut dan menghilangkan yang lainnya. Ini difungsikan agar model tidak belajar pada data yang sama secara berulang ulang, karena hal ini berpotensi terjadinya overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Tweet, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untuk menampilkan data yang  terduplikasi\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hasil tabel di atas menunjukkan ada beberapa data yang terduplikasi. Maka kita pelu menggunakan salah satunya saja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Tweet, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untuk menghilangkan data yang terduplikasi\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# untuk menampilkan data yang terduplikasi\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika tidak ditemukan data yang terduplikasi, maka akan tampak seperti di atas. Akan menghasilkan tabel yang kosong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita perlu menghilangkan data yang hilang nilainya. Bertujuan agar tidak terjadi error ketika melakukan modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index        0\n",
       "Tweet        0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untuk menampilkan data hilang jenis \"Nan\"\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index        0\n",
       "Tweet        0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untuk menampilkan data hilang jenis \"Null\"\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dan untuk memastikan bahwa label tidak ada yang kosong, kita perlu melihat value unik dari labelnya / sentiment. Seharusnya akan mempunyai 3 nilai unik yaitu 0, 1, dan 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan nilai unik data sentiment\n",
    "df[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu pada tahapan ini kita perlu memisahkan antara data yang akan digunakan untuk proses train (data train) dan data yang akan digunakan untuk testing (data testing). Lalu mengapa sebelum case folding dan lain lain ? Karena dalam deploy input yang sebenarnya adalah kalimat. Jadi di model ini kita perlu mlakukan perhitungan ulang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43      Salah satu yang menyebabkan pembatalan ini men...\n",
       "1891    Presiden Jokowi minta Menko Luhut Binsar Pandj...\n",
       "3195    Ppkm aja di perpanjang masa hubungan kita udah...\n",
       "3442    Hidup model apa sih ini. Gua kangen masa nongk...\n",
       "4991    4) pengaturan teknis angka 1) sampai dengan an...\n",
       "                              ...                        \n",
       "3772    Dua Lebih Hemat!\\n\\nGuys jangan lewatkan promo...\n",
       "5191    STICKER CERMIN OVAL 3D STIKER DINDING Kaca Acr...\n",
       "5226    Meskipun #DirumahAja, terus kobarkan semangat ...\n",
       "5390                              #ppkm pie pie kok mawut\n",
       "860     Buat yang masih harus masuk kerja ke kantor, j...\n",
       "Name: Tweet, Length: 4560, dtype: object"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Train_Test_Split(x, y, random_seed=None, test_size=0.2):\n",
    "    n = len(x)\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    " \n",
    "    test_size = int(test_size*n)\n",
    "    indices = np.random.permutation(n)\n",
    "    train_indices, test_indices = indices[test_size:], indices[:test_size]\n",
    "    return x.iloc[train_indices], x.iloc[test_indices], y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "x = df[\"Tweet\"]\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test =Train_Test_Split(x, y, random_seed=42, test_size=0.2)\n",
    "\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada tahapan ini kita akn menghilangkan karakter karakter yang tidak penting seperti tag, hastag, link, dan lain lain. Tahapan ini juga kita akan memperkecil semua huruf agar tidak memiliki makna ganda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43      salah satu yang menyebabkan pembatalan ini men...\n",
       "1891    presiden jokowi minta menko luhut binsar pandj...\n",
       "3195    ppkm aja di perpanjang masa hubungan kita udahan \n",
       "3442    hidup model apa sih ini gua kangen masa nongkr...\n",
       "4991     pengaturan teknis angka  sampai dengan angka ...\n",
       "                              ...                        \n",
       "3772    dua lebih hematguys jangan lewatkan promo dari...\n",
       "5191    sticker cermin oval d stiker dinding kaca acry...\n",
       "5226    meskipun  terus kobarkan semangat kemerdekaan ...\n",
       "5390                                    pie pie kok mawut\n",
       "860     buat yang masih harus masuk kerja ke kantor ja...\n",
       "Name: Tweet, Length: 4560, dtype: object"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def case_folding(text):\n",
    "    # untuk menghilangkan tag atau yang memiliki karakter @\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", text)\n",
    "\n",
    "    # untuk menghilangkan hastag / tagar\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "\n",
    "    # untuk menghilangkan element angka\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # untuk menghilangan RT pada tweet\n",
    "    text = re.sub(r\"RT[\\s]+\", \"\", text)\n",
    "\n",
    "    # untuk menghilangkan link\n",
    "    text = re.sub(r\"https?://\\S+\", \"\", text)\n",
    "\n",
    "    # untuk menghilangkan enter\n",
    "    text = re.sub(r\"\\n+\", \"\", text)\n",
    "\n",
    "    # menghilangkan emoji dan simbol\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # simbol & piktogram\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transportasi & simbol map\n",
    "                               u\"\\U00010000-\\U0010ffff\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "\n",
    "    # untuk menghilangkan simbol simbol\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    return text\n",
    "\n",
    "# mengimplementasikan pada setiap dokumen\n",
    "X_train = X_train.apply(case_folding).str.lower()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ohhh ternyata yg dilanjut PPKM , hubungan kita engga ..🤔\\n\\n#PPKM Diperpanjang'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan sebelum case folding\n",
    "df.loc[36].Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohhh ternyata yg dilanjut ppkm  hubungan kita engga  diperpanjang'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan setelah case folding\n",
    "X_train.loc[36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tahapan ini, kita akan memisahkan sebuah kalimat menjadi per kata untuk menjadikan kata tersebut sebagai atribut x. Jadi atribut tersebut dapat lebih jelas dan dapat diproses oleh model machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43      [salah, satu, yang, menyebabkan, pembatalan, i...\n",
       "1891    [presiden, jokowi, minta, menko, luhut, binsar...\n",
       "3195    [ppkm, aja, di, perpanjang, masa, hubungan, ki...\n",
       "3442    [hidup, model, apa, sih, ini, gua, kangen, mas...\n",
       "4991    [pengaturan, teknis, angka, sampai, dengan, an...\n",
       "                              ...                        \n",
       "3772    [dua, lebih, hematguys, jangan, lewatkan, prom...\n",
       "5191    [sticker, cermin, oval, d, stiker, dinding, ka...\n",
       "5226    [meskipun, terus, kobarkan, semangat, kemerdek...\n",
       "5390                               [pie, pie, kok, mawut]\n",
       "860     [buat, yang, masih, harus, masuk, kerja, ke, k...\n",
       "Name: Tweet, Length: 4560, dtype: object"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memisahkannya dengan nltk\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# mengimplementasikannya untuk setiap dokumen\n",
    "X_train = X_train.apply(tokenize)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tahapan ini kita akan membuat agar kata kata yang maknanya dependen (tidak berdiri sendiri), Seperti kata hubung, kata sifat, dan lain lain akan dihilangkan. Karena pada tahap tokenize sudah dipindahkan menjadi perkata. Maka kata tersebut harus independen maknanya.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun']\n"
     ]
    }
   ],
   "source": [
    "stopword_remover = StopWordRemoverFactory()\n",
    "arr = stopword_remover.create_stop_word_remover()\n",
    "print(stopword_remover.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43      [salah, satu, menyebabkan, pembatalan, tito, k...\n",
       "1891    [presiden, jokowi, minta, menko, luhut, binsar...\n",
       "3195      [ppkm, aja, perpanjang, masa, hubungan, udahan]\n",
       "3442    [hidup, model, apa, sih, gua, kangen, masa, no...\n",
       "4991    [pengaturan, teknis, angka, angka, diatur, pem...\n",
       "                              ...                        \n",
       "3772    [lebih, hematguys, jangan, lewatkan, promo, mc...\n",
       "5191    [sticker, cermin, oval, d, stiker, dinding, ka...\n",
       "5226    [meskipun, terus, kobarkan, semangat, kemerdek...\n",
       "5390                               [pie, pie, kok, mawut]\n",
       "860     [buat, masuk, kerja, kantor, jangan, lengah, s...\n",
       "Name: Tweet, Length: 4560, dtype: object"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# factory / object yang akan membuat stopword\n",
    "stopword_remover = StopWordRemoverFactory()\n",
    "\n",
    "# fungsinya yang akan mengembalikan document yang sudah di stopword\n",
    "def stopword(text):\n",
    "    return [word for word in text if word not in stopword_remover.get_stop_words()]\n",
    "\n",
    "# mengimplementasikan pada setiap dokumen\n",
    "X_train = X_train.apply(stopword)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tahapan ini, kita akan membuat agar semua kata yang memiliki imbuhan untuk dijadikan kata aslinya. Misal Memasak menjadi masak, Penyanyi menjadi nyanyi, Membalap menjadi balap. Tujuannya adalah agar menjadikan kata tersebut menjadi makna yang benar benar dasar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menyiapkan stemmer \n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# menyiapkan function yang akan mengembalikan document yang sudah di stem\n",
    "def stemming(text):\n",
    "    return [stemmer.stem(word) for word in text]\n",
    "\n",
    "# mengimplementasikan pada setiap dokumen\n",
    "X_train = X_train.apply(stemming)\n",
    "\n",
    "# membuat copy an untuk berjaga jaga\n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salah'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untuk menyimpan ke csv, agar tidak dilakukan stemming terus menerus\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "X_train.to_csv(\"stem.csv\", index=False)\n",
    "\n",
    "X_train[\"Tweet\"].iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [salah, satu, sebab, batal, tito, karnavian, d...\n",
       "1       [presiden, jokowi, minta, menko, luhut, binsar...\n",
       "2              [ppkm, aja, panjang, masa, hubung, udahan]\n",
       "3       [hidup, model, apa, sih, gua, kangen, masa, no...\n",
       "4       [atur, teknis, angka, angka, atur, perintah, d...\n",
       "                              ...                        \n",
       "4555    [lebih, hematguys, jangan, lewat, promo, mcdon...\n",
       "4556    [sticker, cermin, oval, d, stiker, dinding, ka...\n",
       "4557    [meski, terus, kobar, semangat, merdeka, kobar...\n",
       "4558                               [pie, pie, kok, mawut]\n",
       "4559    [buat, masuk, kerja, kantor, jangan, lengah, s...\n",
       "Name: Tweet, Length: 4560, dtype: object"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengambul X_train untuk mengupdate\n",
    "X_train = pd.read_csv(\"stem.csv\")[\"Tweet\"].apply(lambda x: x.replace(\"'\", \"\").strip(\"][\").split(\", \"))\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembobotan Kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisa dengan wordcloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dalam tahapan ini, kita akan menganalisa kata apa yang sering muncul di tweet positif dan kata apa yang sering muncul di tweet negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[salah, satu, sebab, batal, tito, karnavian, d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>[presiden, jokowi, minta, menko, luhut, binsar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>[ppkm, aja, panjang, masa, hubung, udahan]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>[hidup, model, apa, sih, gua, kangen, masa, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>[atur, teknis, angka, angka, atur, perintah, d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Labels\n",
       "43    [salah, satu, sebab, batal, tito, karnavian, d...       2\n",
       "1891  [presiden, jokowi, minta, menko, luhut, binsar...       1\n",
       "3195         [ppkm, aja, panjang, masa, hubung, udahan]       2\n",
       "3442  [hidup, model, apa, sih, gua, kangen, masa, no...       0\n",
       "4991  [atur, teknis, angka, angka, atur, perintah, d...       1"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengcopy data train x\n",
    "labeled_data = X_train.copy()\n",
    "\n",
    "# melabeli setiap item\n",
    "labeled_data[\"Labels\"] = y_train.apply(lambda x: int(x))\n",
    "\n",
    "labeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "berikut untuk kata kata yang sering muncul di tweet positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = WordCloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Word On Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF - IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
