{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import gym as gym\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>bandwidth_inbound</th>\n",
       "      <th>bandwidth_outbound</th>\n",
       "      <th>tps</th>\n",
       "      <th>tps_error</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08 01:16:00</td>\n",
       "      <td>1694110560000</td>\n",
       "      <td>9.00%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>7.46 GB/s</td>\n",
       "      <td>6.45 GB/s</td>\n",
       "      <td>2 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>607 ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-08 01:16:05</td>\n",
       "      <td>1694110565000</td>\n",
       "      <td>16.6%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>5.85 GB/s</td>\n",
       "      <td>5.27 GB/s</td>\n",
       "      <td>2.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>2.09 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-08 01:16:10</td>\n",
       "      <td>1694110570000</td>\n",
       "      <td>20.2%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>9.06 GB/s</td>\n",
       "      <td>7.96 GB/s</td>\n",
       "      <td>3.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>3.45 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-08 01:16:15</td>\n",
       "      <td>1694110575000</td>\n",
       "      <td>14.6%</td>\n",
       "      <td>58.0%</td>\n",
       "      <td>8.41 GB/s</td>\n",
       "      <td>7.21 GB/s</td>\n",
       "      <td>3.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>2.58 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-08 01:16:20</td>\n",
       "      <td>1694110580000</td>\n",
       "      <td>10.2%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>4.88 GB/s</td>\n",
       "      <td>4.30 GB/s</td>\n",
       "      <td>2.60 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>862 ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2023-09-08 11:14:40</td>\n",
       "      <td>1694146480000</td>\n",
       "      <td>22.2%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>6.52 GB/s</td>\n",
       "      <td>5.67 GB/s</td>\n",
       "      <td>2.40 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>1.51 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>2023-09-08 11:14:45</td>\n",
       "      <td>1694146485000</td>\n",
       "      <td>27.2%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>7.37 GB/s</td>\n",
       "      <td>6.49 GB/s</td>\n",
       "      <td>2.60 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>1.21 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>2023-09-08 11:14:50</td>\n",
       "      <td>1694146490000</td>\n",
       "      <td>7.20%</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>4.76 GB/s</td>\n",
       "      <td>4.02 GB/s</td>\n",
       "      <td>1.40 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>285 ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>2023-09-08 11:14:55</td>\n",
       "      <td>1694146495000</td>\n",
       "      <td>23.4%</td>\n",
       "      <td>54.6%</td>\n",
       "      <td>6.75 GB/s</td>\n",
       "      <td>5.90 GB/s</td>\n",
       "      <td>2.40 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>804 ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>2023-09-08 11:15:00</td>\n",
       "      <td>1694146500000</td>\n",
       "      <td>31.0%</td>\n",
       "      <td>53.8%</td>\n",
       "      <td>7.76 GB/s</td>\n",
       "      <td>6.92 GB/s</td>\n",
       "      <td>3.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>2.64 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7189 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time      Timestamp cpu_usage memory_usage  \\\n",
       "0     2023-09-08 01:16:00  1694110560000     9.00%        53.5%   \n",
       "1     2023-09-08 01:16:05  1694110565000     16.6%        53.3%   \n",
       "2     2023-09-08 01:16:10  1694110570000     20.2%        55.3%   \n",
       "3     2023-09-08 01:16:15  1694110575000     14.6%        58.0%   \n",
       "4     2023-09-08 01:16:20  1694110580000     10.2%        53.5%   \n",
       "...                   ...            ...       ...          ...   \n",
       "7184  2023-09-08 11:14:40  1694146480000     22.2%        53.5%   \n",
       "7185  2023-09-08 11:14:45  1694146485000     27.2%        56.0%   \n",
       "7186  2023-09-08 11:14:50  1694146490000     7.20%        54.1%   \n",
       "7187  2023-09-08 11:14:55  1694146495000     23.4%        54.6%   \n",
       "7188  2023-09-08 11:15:00  1694146500000     31.0%        53.8%   \n",
       "\n",
       "     bandwidth_inbound bandwidth_outbound         tps tps_error response_time  \\\n",
       "0            7.46 GB/s          6.45 GB/s     2 req/s   0 req/s        607 ms   \n",
       "1            5.85 GB/s          5.27 GB/s  2.20 req/s   0 req/s        2.09 s   \n",
       "2            9.06 GB/s          7.96 GB/s  3.20 req/s   0 req/s        3.45 s   \n",
       "3            8.41 GB/s          7.21 GB/s  3.20 req/s   0 req/s        2.58 s   \n",
       "4            4.88 GB/s          4.30 GB/s  2.60 req/s   0 req/s        862 ms   \n",
       "...                ...                ...         ...       ...           ...   \n",
       "7184         6.52 GB/s          5.67 GB/s  2.40 req/s   0 req/s        1.51 s   \n",
       "7185         7.37 GB/s          6.49 GB/s  2.60 req/s   0 req/s        1.21 s   \n",
       "7186         4.76 GB/s          4.02 GB/s  1.40 req/s   0 req/s        285 ms   \n",
       "7187         6.75 GB/s          5.90 GB/s  2.40 req/s   0 req/s        804 ms   \n",
       "7188         7.76 GB/s          6.92 GB/s  3.20 req/s   0 req/s        2.64 s   \n",
       "\n",
       "      Status  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "7184       0  \n",
       "7185       0  \n",
       "7186       0  \n",
       "7187       0  \n",
       "7188       0  \n",
       "\n",
       "[7189 rows x 10 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"metrics-with-output.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>bandwidth_inbound</th>\n",
       "      <th>bandwidth_outbound</th>\n",
       "      <th>tps</th>\n",
       "      <th>tps_error</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08 01:16:00</td>\n",
       "      <td>1694110560000</td>\n",
       "      <td>9.00%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>7.46 GB/s</td>\n",
       "      <td>6.45 GB/s</td>\n",
       "      <td>2 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>607 ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-08 01:16:05</td>\n",
       "      <td>1694110565000</td>\n",
       "      <td>16.6%</td>\n",
       "      <td>53.3%</td>\n",
       "      <td>5.85 GB/s</td>\n",
       "      <td>5.27 GB/s</td>\n",
       "      <td>2.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>2.09 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-08 01:16:10</td>\n",
       "      <td>1694110570000</td>\n",
       "      <td>20.2%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>9.06 GB/s</td>\n",
       "      <td>7.96 GB/s</td>\n",
       "      <td>3.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>3.45 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-08 01:16:15</td>\n",
       "      <td>1694110575000</td>\n",
       "      <td>14.6%</td>\n",
       "      <td>58.0%</td>\n",
       "      <td>8.41 GB/s</td>\n",
       "      <td>7.21 GB/s</td>\n",
       "      <td>3.20 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>2.58 s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-08 01:16:20</td>\n",
       "      <td>1694110580000</td>\n",
       "      <td>10.2%</td>\n",
       "      <td>53.5%</td>\n",
       "      <td>4.88 GB/s</td>\n",
       "      <td>4.30 GB/s</td>\n",
       "      <td>2.60 req/s</td>\n",
       "      <td>0 req/s</td>\n",
       "      <td>862 ms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time      Timestamp cpu_usage memory_usage  \\\n",
       "0  2023-09-08 01:16:00  1694110560000     9.00%        53.5%   \n",
       "1  2023-09-08 01:16:05  1694110565000     16.6%        53.3%   \n",
       "2  2023-09-08 01:16:10  1694110570000     20.2%        55.3%   \n",
       "3  2023-09-08 01:16:15  1694110575000     14.6%        58.0%   \n",
       "4  2023-09-08 01:16:20  1694110580000     10.2%        53.5%   \n",
       "\n",
       "  bandwidth_inbound bandwidth_outbound         tps tps_error response_time  \\\n",
       "0         7.46 GB/s          6.45 GB/s     2 req/s   0 req/s        607 ms   \n",
       "1         5.85 GB/s          5.27 GB/s  2.20 req/s   0 req/s        2.09 s   \n",
       "2         9.06 GB/s          7.96 GB/s  3.20 req/s   0 req/s        3.45 s   \n",
       "3         8.41 GB/s          7.21 GB/s  3.20 req/s   0 req/s        2.58 s   \n",
       "4         4.88 GB/s          4.30 GB/s  2.60 req/s   0 req/s        862 ms   \n",
       "\n",
       "   Status  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan baris pertama dari data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Membandingkan jumlah status healthy dan unhealthy dengan donut chart\n",
    "status_counts = df['Status'].value_counts()\n",
    "\n",
    "colors = ['red', 'blue']\n",
    "plt.pie(status_counts, labels=status_counts.index, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "# menambahkan lingkaran tengah untuk membuat donut chart\n",
    "plt.gca().add_artist(plt.Circle((0,0), 0.70, fc='white'))\n",
    "# memastikan lingkaran berukuran sama sehingga terlihat seperti donus\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.title('Distribution of Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time                  object\n",
      "Timestamp              int64\n",
      "cpu_usage             object\n",
      "memory_usage          object\n",
      "bandwidth_inbound     object\n",
      "bandwidth_outbound    object\n",
      "tps                   object\n",
      "tps_error             object\n",
      "response_time         object\n",
      "Status                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "# Konversi dataset\n",
    "df['cpu_usage'] = df['cpu_usage'].str.rstrip('%').astype(float) / 100.0\n",
    "df['memory_usage'] = df['memory_usage'].str.rstrip('%').astype('float') / 100.0\n",
    "def clean_bandwidth(value):\n",
    "    if 'GB/s' in value:\n",
    "        return float(value.replace('GB/s', ''))\n",
    "    elif 'MB/s' in value:\n",
    "        return float(value.replace('MB/s', '')) / 1024  # Mengubah MB/s menjadi GB/s\n",
    "    else:\n",
    "        return float(value)\n",
    "\n",
    "df['bandwidth_inbound'] = df['bandwidth_inbound'].apply(clean_bandwidth)\n",
    "df['bandwidth_outbound'] = df['bandwidth_outbound'].apply(clean_bandwidth)\n",
    "df['tps'] = df['tps'].str.rstrip(' req/s').astype('float')\n",
    "df['tps_error'] = df['tps_error'].str.rstrip(' req/s').astype('float')\n",
    "df['response_time'] = df['response_time'].replace({' ms': '*1e-3', ' s': '*1'}, regex=True).map(pd.eval).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7189 entries, 0 to 7188\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Time                7189 non-null   object \n",
      " 1   Timestamp           7189 non-null   int64  \n",
      " 2   cpu_usage           7189 non-null   float64\n",
      " 3   memory_usage        7189 non-null   float64\n",
      " 4   bandwidth_inbound   7189 non-null   float64\n",
      " 5   bandwidth_outbound  7189 non-null   float64\n",
      " 6   tps                 7189 non-null   float64\n",
      " 7   tps_error           7189 non-null   float64\n",
      " 8   response_time       7189 non-null   float64\n",
      " 9   Status              7189 non-null   int64  \n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 561.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Info dataset mengenai tipe, jumlah kolom, dll\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Time      Timestamp  cpu_usage  memory_usage  \\\n",
      "0     2023-09-08 01:16:00  1694110560000      0.090         0.535   \n",
      "1     2023-09-08 01:16:05  1694110565000      0.166         0.533   \n",
      "2     2023-09-08 01:16:10  1694110570000      0.202         0.553   \n",
      "3     2023-09-08 01:16:15  1694110575000      0.146         0.580   \n",
      "4     2023-09-08 01:16:20  1694110580000      0.102         0.535   \n",
      "...                   ...            ...        ...           ...   \n",
      "7184  2023-09-08 11:14:40  1694146480000      0.222         0.535   \n",
      "7185  2023-09-08 11:14:45  1694146485000      0.272         0.560   \n",
      "7186  2023-09-08 11:14:50  1694146490000      0.072         0.541   \n",
      "7187  2023-09-08 11:14:55  1694146495000      0.234         0.546   \n",
      "7188  2023-09-08 11:15:00  1694146500000      0.310         0.538   \n",
      "\n",
      "      bandwidth_inbound  bandwidth_outbound  tps  tps_error  response_time  \\\n",
      "0                  7.46                6.45  2.0        0.0          0.607   \n",
      "1                  5.85                5.27  2.2        0.0          2.090   \n",
      "2                  9.06                7.96  3.2        0.0          3.450   \n",
      "3                  8.41                7.21  3.2        0.0          2.580   \n",
      "4                  4.88                4.30  2.6        0.0          0.862   \n",
      "...                 ...                 ...  ...        ...            ...   \n",
      "7184               6.52                5.67  2.4        0.0          1.510   \n",
      "7185               7.37                6.49  2.6        0.0          1.210   \n",
      "7186               4.76                4.02  1.4        0.0          0.285   \n",
      "7187               6.75                5.90  2.4        0.0          0.804   \n",
      "7188               7.76                6.92  3.2        0.0          2.640   \n",
      "\n",
      "      Status  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "...      ...  \n",
      "7184       0  \n",
      "7185       0  \n",
      "7186       0  \n",
      "7187       0  \n",
      "7188       0  \n",
      "\n",
      "[7189 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan dataset setelah konversi\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>bandwidth_inbound</th>\n",
       "      <th>bandwidth_outbound</th>\n",
       "      <th>tps</th>\n",
       "      <th>tps_error</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "      <td>7189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.163090</td>\n",
       "      <td>0.542723</td>\n",
       "      <td>6.318377</td>\n",
       "      <td>5.573617</td>\n",
       "      <td>2.490218</td>\n",
       "      <td>0.170817</td>\n",
       "      <td>1.770724</td>\n",
       "      <td>0.132981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.069272</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>3.193037</td>\n",
       "      <td>2.728239</td>\n",
       "      <td>0.784028</td>\n",
       "      <td>0.548970</td>\n",
       "      <td>1.024615</td>\n",
       "      <td>0.339578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.056055</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>5.910000</td>\n",
       "      <td>5.230000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>8.310000</td>\n",
       "      <td>7.260000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cpu_usage  memory_usage  bandwidth_inbound  bandwidth_outbound  \\\n",
       "count  7189.000000   7189.000000        7189.000000         7189.000000   \n",
       "mean      0.163090      0.542723           6.318377            5.573617   \n",
       "std       0.069272      0.019356           3.193037            2.728239   \n",
       "min       0.010000      0.497000           0.056055            0.060645   \n",
       "25%       0.118000      0.533000           3.940000            3.540000   \n",
       "50%       0.156000      0.539000           5.910000            5.230000   \n",
       "75%       0.198000      0.549000           8.310000            7.260000   \n",
       "max       1.000000      0.700000          20.400000           17.600000   \n",
       "\n",
       "               tps    tps_error  response_time       Status  \n",
       "count  7189.000000  7189.000000    7189.000000  7189.000000  \n",
       "mean      2.490218     0.170817       1.770724     0.132981  \n",
       "std       0.784028     0.548970       1.024615     0.339578  \n",
       "min       0.600000     0.000000       0.118000     0.000000  \n",
       "25%       2.000000     0.000000       0.952000     0.000000  \n",
       "50%       2.400000     0.000000       1.520000     0.000000  \n",
       "75%       3.000000     0.000000       2.450000     0.000000  \n",
       "max       5.800000     4.600000       7.100000     1.000000  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembersihan dan penghapusan data yang tidak dipakai\n",
    "dataset = df.drop(df.columns[[0, 1]], axis=1)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode Status ke numerik\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['Status'] = label_encoder.fit_transform(dataset['Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "7184    0\n",
       "7185    0\n",
       "7186    0\n",
       "7187    0\n",
       "7188    0\n",
       "Name: Status, Length: 7189, dtype: int64"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada missing values dalam dataset\n"
     ]
    }
   ],
   "source": [
    "# Periksa apakah ada data yang hilang\n",
    "missing_data = dataset.isnull().sum()\n",
    "if missing_data.any():\n",
    "    print(\"Terdapat missing values yang perlu diimputasi\")\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print(\"Tidak ada missing values dalam dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi feature (X) dan target (y)\n",
    "X = dataset.drop('Status', axis=1)\n",
    "y = dataset['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19191919, 0.43842365, 0.59693167, ..., 0.5       , 0.        ,\n",
       "        0.44714981],\n",
       "       [0.11919192, 0.1773399 , 0.21303367, ..., 0.30769231, 0.        ,\n",
       "        0.17788599],\n",
       "       [0.17777778, 0.21674877, 0.63625541, ..., 0.5       , 0.        ,\n",
       "        0.05299341],\n",
       "       ...,\n",
       "       [0.22828283, 0.16748768, 0.28824032, ..., 0.57692308, 0.        ,\n",
       "        0.1807505 ],\n",
       "       [0.4040404 , 0.73399015, 0.94592986, ..., 0.42307692, 0.        ,\n",
       "        0.24949871],\n",
       "       [0.04848485, 0.16748768, 0.0503317 , ..., 0.46153846, 0.43478261,\n",
       "        0.45717559]])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan model ppo\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr=0.0003, gamma=0.99, k_epochs=4, eps_clip=0.2):\n",
    "        self.policy = PolicyNetwork(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.policy_old = PolicyNetwork(state_dim, action_dim)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        self.MseLoss = nn.MSELoss()\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.k_epochs = k_epochs\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action_probs = torch.softmax(self.policy_old(state), dim=-1)\n",
    "        dist = Categorical(action_probs)\n",
    "        action = dist.sample()\n",
    "        return action.item(), dist.log_prob(action).item()\n",
    "    \n",
    "    def update(self, memory):\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(memory.rewards), reversed(memory.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "        \n",
    "        # Normalisasi rewards:\n",
    "        rewards = torch.tensor(rewards)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n",
    "        \n",
    "        # Konversi list ke tensor\n",
    "        old_states = torch.squeeze(torch.stack(memory.states, dim=0)).detach()\n",
    "        old_actions = torch.squeeze(torch.stack(memory.actions, dim=0)).detach()\n",
    "        old_logprobs = torch.squeeze(torch.stack(memory.logprobs, dim=0)).detach()\n",
    "        \n",
    "        # Optimisasi policy:\n",
    "        for _ in range(self.k_epochs):\n",
    "            logprobs = []\n",
    "            state_values = []\n",
    "            dist_entropy = []\n",
    "            for state in old_states:\n",
    "                action_probs = torch.softmax(self.policy(state), dim=-1)\n",
    "                dist = Categorical(action_probs)\n",
    "                logprob = dist.log_prob(old_actions)\n",
    "                entropy = dist.entropy()\n",
    "                \n",
    "                logprobs.append(logprob)\n",
    "                dist_entropy.append(entropy)\n",
    "            \n",
    "            logprobs = torch.stack(logprobs)\n",
    "            dist_entropy = torch.stack(dist_entropy)\n",
    "            \n",
    "            ratios = torch.exp(logprobs - old_logprobs)\n",
    "            \n",
    "            advantages = rewards - rewards.mean()\n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            state_values = torch.zeros_like(rewards)\n",
    "            for i, state in enumerate(old_states):\n",
    "                state_values[i] = self.policy(state).max()\n",
    "            \n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy.mean()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "\n",
    "    def clear_memory(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "    def add_action(self, action):\n",
    "        self.actions.append(action)\n",
    "\n",
    "    def add_state(self, state):\n",
    "        self.states.append(state)\n",
    "\n",
    "    def add_logprob(self, logprob):\n",
    "        self.logprobs.append(logprob)\n",
    "\n",
    "    def add_reward(self, reward):\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def add_is_terminal(self, is_terminal):\n",
    "        self.is_terminals.append(is_terminal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan Environment\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(CustomEnv, self).__init__()\n",
    "\n",
    "        # Load data dari data set\n",
    "        self.df = dataset\n",
    "\n",
    "        # Mendefinisikan action dan observation space\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(7,), dtype=np.float64)\n",
    "\n",
    "        self.current_step = 0  # typo corrected\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "\n",
    "        reward = self._get_reward(action)\n",
    "        next_state = self._get_observation()\n",
    "        \n",
    "        return next_state, reward, done, {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        return self.df.iloc[self.current_step][['cpu_usage', 'memory_usage', 'bandwidth_inbound', 'bandwidth_outbound', 'tps', 'tps_error', 'response_time']].values\n",
    "    \n",
    "    def _get_reward(self, action):\n",
    "        # Define reward logic, e.g., based on action and actual status\n",
    "        if action == self.df.iloc[self.current_step]['Status']:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 \t Total reward: 743.0\n",
      "Episode 2 \t Total reward: 887.0\n",
      "Episode 3 \t Total reward: 988.0\n",
      "Episode 4 \t Total reward: 1099.0\n",
      "Episode 5 \t Total reward: 1183.0\n",
      "Episode 6 \t Total reward: 1163.0\n",
      "Episode 7 \t Total reward: 1127.0\n",
      "Episode 8 \t Total reward: 1194.0\n",
      "Episode 9 \t Total reward: 1196.0\n",
      "Episode 10 \t Total reward: 1198.0\n",
      "Episode 11 \t Total reward: 1200.0\n",
      "Episode 12 \t Total reward: 1211.0\n",
      "Episode 13 \t Total reward: 1259.0\n",
      "Episode 14 \t Total reward: 1228.0\n",
      "Episode 15 \t Total reward: 1288.0\n",
      "Episode 16 \t Total reward: 1251.0\n",
      "Episode 17 \t Total reward: 1276.0\n",
      "Episode 18 \t Total reward: 1303.0\n",
      "Episode 19 \t Total reward: 1282.0\n",
      "Episode 20 \t Total reward: 1337.0\n",
      "Episode 21 \t Total reward: 1398.0\n",
      "Episode 22 \t Total reward: 1385.0\n",
      "Episode 23 \t Total reward: 1426.0\n",
      "Episode 24 \t Total reward: 1457.0\n",
      "Episode 25 \t Total reward: 1410.0\n",
      "Episode 26 \t Total reward: 1427.0\n",
      "Episode 27 \t Total reward: 1436.0\n",
      "Episode 28 \t Total reward: 1406.0\n",
      "Episode 29 \t Total reward: 1444.0\n",
      "Episode 30 \t Total reward: 1404.0\n",
      "Episode 31 \t Total reward: 1406.0\n",
      "Episode 32 \t Total reward: 1424.0\n",
      "Episode 33 \t Total reward: 1391.0\n",
      "Episode 34 \t Total reward: 1402.0\n",
      "Episode 35 \t Total reward: 1467.0\n",
      "Episode 36 \t Total reward: 1486.0\n",
      "Episode 37 \t Total reward: 1470.0\n",
      "Episode 38 \t Total reward: 1477.0\n",
      "Episode 39 \t Total reward: 1495.0\n",
      "Episode 40 \t Total reward: 1504.0\n",
      "Episode 41 \t Total reward: 1514.0\n",
      "Episode 42 \t Total reward: 1536.0\n",
      "Episode 43 \t Total reward: 1551.0\n",
      "Episode 44 \t Total reward: 1562.0\n",
      "Episode 45 \t Total reward: 1576.0\n",
      "Episode 46 \t Total reward: 1622.0\n",
      "Episode 47 \t Total reward: 1618.0\n",
      "Episode 48 \t Total reward: 1623.0\n",
      "Episode 49 \t Total reward: 1637.0\n",
      "Episode 50 \t Total reward: 1629.0\n",
      "Episode 51 \t Total reward: 1630.0\n",
      "Episode 52 \t Total reward: 1618.0\n",
      "Episode 53 \t Total reward: 1617.0\n",
      "Episode 54 \t Total reward: 1611.0\n",
      "Episode 55 \t Total reward: 1632.0\n",
      "Episode 56 \t Total reward: 1635.0\n",
      "Episode 57 \t Total reward: 1638.0\n",
      "Episode 58 \t Total reward: 1636.0\n",
      "Episode 59 \t Total reward: 1653.0\n",
      "Episode 60 \t Total reward: 1678.0\n",
      "Episode 61 \t Total reward: 1684.0\n",
      "Episode 62 \t Total reward: 1695.0\n",
      "Episode 63 \t Total reward: 1679.0\n",
      "Episode 64 \t Total reward: 1697.0\n",
      "Episode 65 \t Total reward: 1695.0\n",
      "Episode 66 \t Total reward: 1683.0\n",
      "Episode 67 \t Total reward: 1711.0\n",
      "Episode 68 \t Total reward: 1712.0\n",
      "Episode 69 \t Total reward: 1717.0\n",
      "Episode 70 \t Total reward: 1726.0\n",
      "Episode 71 \t Total reward: 1710.0\n",
      "Episode 72 \t Total reward: 1719.0\n",
      "Episode 73 \t Total reward: 1712.0\n",
      "Episode 74 \t Total reward: 1725.0\n",
      "Episode 75 \t Total reward: 1722.0\n",
      "Episode 76 \t Total reward: 1719.0\n",
      "Episode 77 \t Total reward: 1721.0\n",
      "Episode 78 \t Total reward: 1741.0\n",
      "Episode 79 \t Total reward: 1734.0\n",
      "Episode 80 \t Total reward: 1731.0\n",
      "Episode 81 \t Total reward: 1727.0\n",
      "Episode 82 \t Total reward: 1734.0\n",
      "Episode 83 \t Total reward: 1736.0\n",
      "Episode 84 \t Total reward: 1736.0\n",
      "Episode 85 \t Total reward: 1732.0\n",
      "Episode 86 \t Total reward: 1744.0\n",
      "Episode 87 \t Total reward: 1745.0\n",
      "Episode 88 \t Total reward: 1737.0\n",
      "Episode 89 \t Total reward: 1736.0\n",
      "Episode 90 \t Total reward: 1734.0\n",
      "Episode 91 \t Total reward: 1741.0\n",
      "Episode 92 \t Total reward: 1746.0\n",
      "Episode 93 \t Total reward: 1754.0\n",
      "Episode 94 \t Total reward: 1758.0\n",
      "Episode 95 \t Total reward: 1758.0\n",
      "Episode 96 \t Total reward: 1757.0\n",
      "Episode 97 \t Total reward: 1765.0\n",
      "Episode 98 \t Total reward: 1763.0\n",
      "Episode 99 \t Total reward: 1768.0\n",
      "Episode 100 \t Total reward: 1757.0\n",
      "Episode 101 \t Total reward: 1763.0\n",
      "Episode 102 \t Total reward: 1766.0\n",
      "Episode 103 \t Total reward: 1763.0\n",
      "Episode 104 \t Total reward: 1763.0\n",
      "Episode 105 \t Total reward: 1766.0\n",
      "Episode 106 \t Total reward: 1763.0\n",
      "Episode 107 \t Total reward: 1767.0\n",
      "Episode 108 \t Total reward: 1769.0\n",
      "Episode 109 \t Total reward: 1772.0\n",
      "Episode 110 \t Total reward: 1769.0\n",
      "Episode 111 \t Total reward: 1765.0\n",
      "Episode 112 \t Total reward: 1763.0\n",
      "Episode 113 \t Total reward: 1766.0\n",
      "Episode 114 \t Total reward: 1762.0\n",
      "Episode 115 \t Total reward: 1772.0\n",
      "Episode 116 \t Total reward: 1768.0\n",
      "Episode 117 \t Total reward: 1766.0\n",
      "Episode 118 \t Total reward: 1770.0\n",
      "Episode 119 \t Total reward: 1769.0\n",
      "Episode 120 \t Total reward: 1774.0\n",
      "Episode 121 \t Total reward: 1775.0\n",
      "Episode 122 \t Total reward: 1775.0\n",
      "Episode 123 \t Total reward: 1771.0\n",
      "Episode 124 \t Total reward: 1772.0\n",
      "Episode 125 \t Total reward: 1770.0\n",
      "Episode 126 \t Total reward: 1769.0\n",
      "Episode 127 \t Total reward: 1771.0\n",
      "Episode 128 \t Total reward: 1769.0\n",
      "Episode 129 \t Total reward: 1764.0\n",
      "Episode 130 \t Total reward: 1769.0\n",
      "Episode 131 \t Total reward: 1767.0\n",
      "Episode 132 \t Total reward: 1768.0\n",
      "Episode 133 \t Total reward: 1772.0\n",
      "Episode 134 \t Total reward: 1768.0\n",
      "Episode 135 \t Total reward: 1772.0\n",
      "Episode 136 \t Total reward: 1770.0\n",
      "Episode 137 \t Total reward: 1770.0\n",
      "Episode 138 \t Total reward: 1768.0\n",
      "Episode 139 \t Total reward: 1769.0\n",
      "Episode 140 \t Total reward: 1771.0\n",
      "Episode 141 \t Total reward: 1769.0\n",
      "Episode 142 \t Total reward: 1767.0\n",
      "Episode 143 \t Total reward: 1769.0\n",
      "Episode 144 \t Total reward: 1762.0\n",
      "Episode 145 \t Total reward: 1772.0\n",
      "Episode 146 \t Total reward: 1769.0\n",
      "Episode 147 \t Total reward: 1767.0\n",
      "Episode 148 \t Total reward: 1774.0\n",
      "Episode 149 \t Total reward: 1772.0\n",
      "Episode 150 \t Total reward: 1776.0\n",
      "Episode 151 \t Total reward: 1770.0\n",
      "Episode 152 \t Total reward: 1772.0\n",
      "Episode 153 \t Total reward: 1772.0\n",
      "Episode 154 \t Total reward: 1769.0\n",
      "Episode 155 \t Total reward: 1775.0\n",
      "Episode 156 \t Total reward: 1774.0\n",
      "Episode 157 \t Total reward: 1771.0\n",
      "Episode 158 \t Total reward: 1768.0\n",
      "Episode 159 \t Total reward: 1770.0\n",
      "Episode 160 \t Total reward: 1775.0\n",
      "Episode 161 \t Total reward: 1769.0\n",
      "Episode 162 \t Total reward: 1765.0\n",
      "Episode 163 \t Total reward: 1771.0\n",
      "Episode 164 \t Total reward: 1769.0\n",
      "Episode 165 \t Total reward: 1770.0\n",
      "Episode 166 \t Total reward: 1772.0\n",
      "Episode 167 \t Total reward: 1769.0\n",
      "Episode 168 \t Total reward: 1773.0\n",
      "Episode 169 \t Total reward: 1773.0\n",
      "Episode 170 \t Total reward: 1766.0\n",
      "Episode 171 \t Total reward: 1771.0\n",
      "Episode 172 \t Total reward: 1774.0\n",
      "Episode 173 \t Total reward: 1771.0\n",
      "Episode 174 \t Total reward: 1774.0\n",
      "Episode 175 \t Total reward: 1774.0\n",
      "Episode 176 \t Total reward: 1775.0\n",
      "Episode 177 \t Total reward: 1768.0\n",
      "Episode 178 \t Total reward: 1771.0\n",
      "Episode 179 \t Total reward: 1771.0\n",
      "Episode 180 \t Total reward: 1766.0\n",
      "Episode 181 \t Total reward: 1771.0\n",
      "Episode 182 \t Total reward: 1768.0\n",
      "Episode 183 \t Total reward: 1771.0\n",
      "Episode 184 \t Total reward: 1769.0\n",
      "Episode 185 \t Total reward: 1770.0\n",
      "Episode 186 \t Total reward: 1770.0\n",
      "Episode 187 \t Total reward: 1769.0\n",
      "Episode 188 \t Total reward: 1772.0\n",
      "Episode 189 \t Total reward: 1769.0\n",
      "Episode 190 \t Total reward: 1770.0\n",
      "Episode 191 \t Total reward: 1773.0\n",
      "Episode 192 \t Total reward: 1770.0\n",
      "Episode 193 \t Total reward: 1770.0\n",
      "Episode 194 \t Total reward: 1772.0\n",
      "Episode 195 \t Total reward: 1768.0\n",
      "Episode 196 \t Total reward: 1771.0\n",
      "Episode 197 \t Total reward: 1771.0\n",
      "Episode 198 \t Total reward: 1772.0\n",
      "Episode 199 \t Total reward: 1768.0\n",
      "Episode 200 \t Total reward: 1772.0\n",
      "Episode 201 \t Total reward: 1775.0\n",
      "Episode 202 \t Total reward: 1774.0\n",
      "Episode 203 \t Total reward: 1776.0\n",
      "Episode 204 \t Total reward: 1774.0\n",
      "Episode 205 \t Total reward: 1776.0\n",
      "Episode 206 \t Total reward: 1776.0\n",
      "Episode 207 \t Total reward: 1774.0\n",
      "Episode 208 \t Total reward: 1776.0\n",
      "Episode 209 \t Total reward: 1774.0\n",
      "Episode 210 \t Total reward: 1774.0\n",
      "Episode 211 \t Total reward: 1775.0\n",
      "Episode 212 \t Total reward: 1774.0\n",
      "Episode 213 \t Total reward: 1775.0\n",
      "Episode 214 \t Total reward: 1772.0\n",
      "Episode 215 \t Total reward: 1775.0\n",
      "Episode 216 \t Total reward: 1775.0\n",
      "Episode 217 \t Total reward: 1776.0\n",
      "Episode 218 \t Total reward: 1775.0\n",
      "Episode 219 \t Total reward: 1778.0\n",
      "Episode 220 \t Total reward: 1772.0\n",
      "Episode 221 \t Total reward: 1774.0\n",
      "Episode 222 \t Total reward: 1776.0\n",
      "Episode 223 \t Total reward: 1773.0\n",
      "Episode 224 \t Total reward: 1773.0\n",
      "Episode 225 \t Total reward: 1775.0\n",
      "Episode 226 \t Total reward: 1774.0\n",
      "Episode 227 \t Total reward: 1774.0\n",
      "Episode 228 \t Total reward: 1774.0\n",
      "Episode 229 \t Total reward: 1774.0\n",
      "Episode 230 \t Total reward: 1774.0\n",
      "Episode 231 \t Total reward: 1776.0\n",
      "Episode 232 \t Total reward: 1773.0\n",
      "Episode 233 \t Total reward: 1774.0\n",
      "Episode 234 \t Total reward: 1776.0\n",
      "Episode 235 \t Total reward: 1776.0\n",
      "Episode 236 \t Total reward: 1773.0\n",
      "Episode 237 \t Total reward: 1775.0\n",
      "Episode 238 \t Total reward: 1774.0\n",
      "Episode 239 \t Total reward: 1775.0\n",
      "Episode 240 \t Total reward: 1777.0\n",
      "Episode 241 \t Total reward: 1777.0\n",
      "Episode 242 \t Total reward: 1776.0\n",
      "Episode 243 \t Total reward: 1775.0\n",
      "Episode 244 \t Total reward: 1776.0\n",
      "Episode 245 \t Total reward: 1775.0\n",
      "Episode 246 \t Total reward: 1776.0\n",
      "Episode 247 \t Total reward: 1775.0\n",
      "Episode 248 \t Total reward: 1772.0\n",
      "Episode 249 \t Total reward: 1775.0\n",
      "Episode 250 \t Total reward: 1772.0\n",
      "Episode 251 \t Total reward: 1775.0\n",
      "Episode 252 \t Total reward: 1776.0\n",
      "Episode 253 \t Total reward: 1773.0\n",
      "Episode 254 \t Total reward: 1774.0\n",
      "Episode 255 \t Total reward: 1775.0\n",
      "Episode 256 \t Total reward: 1773.0\n",
      "Episode 257 \t Total reward: 1773.0\n",
      "Episode 258 \t Total reward: 1775.0\n",
      "Episode 259 \t Total reward: 1775.0\n",
      "Episode 260 \t Total reward: 1776.0\n",
      "Episode 261 \t Total reward: 1774.0\n",
      "Episode 262 \t Total reward: 1772.0\n",
      "Episode 263 \t Total reward: 1774.0\n",
      "Episode 264 \t Total reward: 1773.0\n",
      "Episode 265 \t Total reward: 1775.0\n",
      "Episode 266 \t Total reward: 1773.0\n",
      "Episode 267 \t Total reward: 1776.0\n",
      "Episode 268 \t Total reward: 1776.0\n",
      "Episode 269 \t Total reward: 1771.0\n",
      "Episode 270 \t Total reward: 1775.0\n",
      "Episode 271 \t Total reward: 1771.0\n",
      "Episode 272 \t Total reward: 1774.0\n",
      "Episode 273 \t Total reward: 1776.0\n",
      "Episode 274 \t Total reward: 1776.0\n",
      "Episode 275 \t Total reward: 1774.0\n",
      "Episode 276 \t Total reward: 1777.0\n",
      "Episode 277 \t Total reward: 1774.0\n",
      "Episode 278 \t Total reward: 1775.0\n",
      "Episode 279 \t Total reward: 1775.0\n",
      "Episode 280 \t Total reward: 1775.0\n",
      "Episode 281 \t Total reward: 1774.0\n",
      "Episode 282 \t Total reward: 1775.0\n",
      "Episode 283 \t Total reward: 1775.0\n",
      "Episode 284 \t Total reward: 1772.0\n",
      "Episode 285 \t Total reward: 1775.0\n",
      "Episode 286 \t Total reward: 1775.0\n",
      "Episode 287 \t Total reward: 1776.0\n",
      "Episode 288 \t Total reward: 1774.0\n",
      "Episode 289 \t Total reward: 1775.0\n",
      "Episode 290 \t Total reward: 1774.0\n",
      "Episode 291 \t Total reward: 1776.0\n",
      "Episode 292 \t Total reward: 1776.0\n",
      "Episode 293 \t Total reward: 1774.0\n",
      "Episode 294 \t Total reward: 1775.0\n",
      "Episode 295 \t Total reward: 1772.0\n",
      "Episode 296 \t Total reward: 1774.0\n",
      "Episode 297 \t Total reward: 1775.0\n",
      "Episode 298 \t Total reward: 1775.0\n",
      "Episode 299 \t Total reward: 1775.0\n",
      "Episode 300 \t Total reward: 1772.0\n",
      "Episode 301 \t Total reward: 1774.0\n",
      "Episode 302 \t Total reward: 1772.0\n",
      "Episode 303 \t Total reward: 1774.0\n",
      "Episode 304 \t Total reward: 1775.0\n",
      "Episode 305 \t Total reward: 1773.0\n",
      "Episode 306 \t Total reward: 1775.0\n",
      "Episode 307 \t Total reward: 1775.0\n",
      "Episode 308 \t Total reward: 1772.0\n",
      "Episode 309 \t Total reward: 1773.0\n",
      "Episode 310 \t Total reward: 1776.0\n",
      "Episode 311 \t Total reward: 1775.0\n",
      "Episode 312 \t Total reward: 1774.0\n",
      "Episode 313 \t Total reward: 1775.0\n",
      "Episode 314 \t Total reward: 1777.0\n",
      "Episode 315 \t Total reward: 1776.0\n",
      "Episode 316 \t Total reward: 1775.0\n",
      "Episode 317 \t Total reward: 1777.0\n",
      "Episode 318 \t Total reward: 1775.0\n",
      "Episode 319 \t Total reward: 1773.0\n",
      "Episode 320 \t Total reward: 1774.0\n",
      "Episode 321 \t Total reward: 1774.0\n",
      "Episode 322 \t Total reward: 1771.0\n",
      "Episode 323 \t Total reward: 1773.0\n",
      "Episode 324 \t Total reward: 1774.0\n",
      "Episode 325 \t Total reward: 1774.0\n",
      "Episode 326 \t Total reward: 1774.0\n",
      "Episode 327 \t Total reward: 1776.0\n",
      "Episode 328 \t Total reward: 1776.0\n",
      "Episode 329 \t Total reward: 1776.0\n",
      "Episode 330 \t Total reward: 1774.0\n",
      "Episode 331 \t Total reward: 1774.0\n",
      "Episode 332 \t Total reward: 1776.0\n",
      "Episode 333 \t Total reward: 1776.0\n",
      "Episode 334 \t Total reward: 1776.0\n",
      "Episode 335 \t Total reward: 1776.0\n",
      "Episode 336 \t Total reward: 1773.0\n",
      "Episode 337 \t Total reward: 1775.0\n",
      "Episode 338 \t Total reward: 1776.0\n",
      "Episode 339 \t Total reward: 1772.0\n",
      "Episode 340 \t Total reward: 1776.0\n",
      "Episode 341 \t Total reward: 1775.0\n",
      "Episode 342 \t Total reward: 1776.0\n",
      "Episode 343 \t Total reward: 1774.0\n",
      "Episode 344 \t Total reward: 1776.0\n",
      "Episode 345 \t Total reward: 1774.0\n",
      "Episode 346 \t Total reward: 1776.0\n",
      "Episode 347 \t Total reward: 1776.0\n",
      "Episode 348 \t Total reward: 1776.0\n",
      "Episode 349 \t Total reward: 1776.0\n",
      "Episode 350 \t Total reward: 1776.0\n",
      "Episode 351 \t Total reward: 1776.0\n",
      "Episode 352 \t Total reward: 1775.0\n",
      "Episode 353 \t Total reward: 1776.0\n",
      "Episode 354 \t Total reward: 1775.0\n",
      "Episode 355 \t Total reward: 1776.0\n",
      "Episode 356 \t Total reward: 1776.0\n",
      "Episode 357 \t Total reward: 1776.0\n",
      "Episode 358 \t Total reward: 1776.0\n",
      "Episode 359 \t Total reward: 1773.0\n",
      "Episode 360 \t Total reward: 1775.0\n",
      "Episode 361 \t Total reward: 1776.0\n",
      "Episode 362 \t Total reward: 1775.0\n",
      "Episode 363 \t Total reward: 1776.0\n",
      "Episode 364 \t Total reward: 1776.0\n",
      "Episode 365 \t Total reward: 1776.0\n",
      "Episode 366 \t Total reward: 1776.0\n",
      "Episode 367 \t Total reward: 1776.0\n",
      "Episode 368 \t Total reward: 1776.0\n",
      "Episode 369 \t Total reward: 1775.0\n",
      "Episode 370 \t Total reward: 1776.0\n",
      "Episode 371 \t Total reward: 1776.0\n",
      "Episode 372 \t Total reward: 1774.0\n",
      "Episode 373 \t Total reward: 1776.0\n",
      "Episode 374 \t Total reward: 1775.0\n",
      "Episode 375 \t Total reward: 1775.0\n",
      "Episode 376 \t Total reward: 1776.0\n",
      "Episode 377 \t Total reward: 1775.0\n",
      "Episode 378 \t Total reward: 1775.0\n",
      "Episode 379 \t Total reward: 1775.0\n",
      "Episode 380 \t Total reward: 1776.0\n",
      "Episode 381 \t Total reward: 1775.0\n",
      "Episode 382 \t Total reward: 1776.0\n",
      "Episode 383 \t Total reward: 1776.0\n",
      "Episode 384 \t Total reward: 1775.0\n",
      "Episode 385 \t Total reward: 1776.0\n",
      "Episode 386 \t Total reward: 1776.0\n",
      "Episode 387 \t Total reward: 1776.0\n",
      "Episode 388 \t Total reward: 1774.0\n",
      "Episode 389 \t Total reward: 1775.0\n",
      "Episode 390 \t Total reward: 1775.0\n",
      "Episode 391 \t Total reward: 1775.0\n",
      "Episode 392 \t Total reward: 1776.0\n",
      "Episode 393 \t Total reward: 1776.0\n",
      "Episode 394 \t Total reward: 1776.0\n",
      "Episode 395 \t Total reward: 1776.0\n",
      "Episode 396 \t Total reward: 1776.0\n",
      "Episode 397 \t Total reward: 1774.0\n",
      "Episode 398 \t Total reward: 1776.0\n",
      "Episode 399 \t Total reward: 1775.0\n",
      "Episode 400 \t Total reward: 1776.0\n",
      "Episode 401 \t Total reward: 1776.0\n",
      "Episode 402 \t Total reward: 1776.0\n",
      "Episode 403 \t Total reward: 1776.0\n",
      "Episode 404 \t Total reward: 1775.0\n",
      "Episode 405 \t Total reward: 1775.0\n",
      "Episode 406 \t Total reward: 1776.0\n",
      "Episode 407 \t Total reward: 1776.0\n",
      "Episode 408 \t Total reward: 1776.0\n",
      "Episode 409 \t Total reward: 1776.0\n",
      "Episode 410 \t Total reward: 1776.0\n",
      "Episode 411 \t Total reward: 1776.0\n",
      "Episode 412 \t Total reward: 1775.0\n",
      "Episode 413 \t Total reward: 1776.0\n",
      "Episode 414 \t Total reward: 1775.0\n",
      "Episode 415 \t Total reward: 1776.0\n",
      "Episode 416 \t Total reward: 1777.0\n",
      "Episode 417 \t Total reward: 1776.0\n",
      "Episode 418 \t Total reward: 1776.0\n",
      "Episode 419 \t Total reward: 1775.0\n",
      "Episode 420 \t Total reward: 1775.0\n",
      "Episode 421 \t Total reward: 1776.0\n",
      "Episode 422 \t Total reward: 1774.0\n",
      "Episode 423 \t Total reward: 1775.0\n",
      "Episode 424 \t Total reward: 1776.0\n",
      "Episode 425 \t Total reward: 1776.0\n",
      "Episode 426 \t Total reward: 1776.0\n",
      "Episode 427 \t Total reward: 1776.0\n",
      "Episode 428 \t Total reward: 1776.0\n",
      "Episode 429 \t Total reward: 1776.0\n",
      "Episode 430 \t Total reward: 1776.0\n",
      "Episode 431 \t Total reward: 1776.0\n",
      "Episode 432 \t Total reward: 1776.0\n",
      "Episode 433 \t Total reward: 1775.0\n",
      "Episode 434 \t Total reward: 1776.0\n",
      "Episode 435 \t Total reward: 1776.0\n",
      "Episode 436 \t Total reward: 1776.0\n",
      "Episode 437 \t Total reward: 1776.0\n",
      "Episode 438 \t Total reward: 1776.0\n",
      "Episode 439 \t Total reward: 1777.0\n",
      "Episode 440 \t Total reward: 1774.0\n",
      "Episode 441 \t Total reward: 1775.0\n",
      "Episode 442 \t Total reward: 1776.0\n",
      "Episode 443 \t Total reward: 1776.0\n",
      "Episode 444 \t Total reward: 1776.0\n",
      "Episode 445 \t Total reward: 1776.0\n",
      "Episode 446 \t Total reward: 1776.0\n",
      "Episode 447 \t Total reward: 1776.0\n",
      "Episode 448 \t Total reward: 1776.0\n",
      "Episode 449 \t Total reward: 1776.0\n",
      "Episode 450 \t Total reward: 1776.0\n",
      "Episode 451 \t Total reward: 1776.0\n",
      "Episode 452 \t Total reward: 1775.0\n",
      "Episode 453 \t Total reward: 1777.0\n",
      "Episode 454 \t Total reward: 1776.0\n",
      "Episode 455 \t Total reward: 1776.0\n",
      "Episode 456 \t Total reward: 1776.0\n",
      "Episode 457 \t Total reward: 1776.0\n",
      "Episode 458 \t Total reward: 1775.0\n",
      "Episode 459 \t Total reward: 1775.0\n",
      "Episode 460 \t Total reward: 1776.0\n",
      "Episode 461 \t Total reward: 1775.0\n",
      "Episode 462 \t Total reward: 1775.0\n",
      "Episode 463 \t Total reward: 1775.0\n",
      "Episode 464 \t Total reward: 1774.0\n",
      "Episode 465 \t Total reward: 1776.0\n",
      "Episode 466 \t Total reward: 1775.0\n",
      "Episode 467 \t Total reward: 1776.0\n",
      "Episode 468 \t Total reward: 1776.0\n",
      "Episode 469 \t Total reward: 1776.0\n",
      "Episode 470 \t Total reward: 1776.0\n",
      "Episode 471 \t Total reward: 1776.0\n",
      "Episode 472 \t Total reward: 1775.0\n",
      "Episode 473 \t Total reward: 1776.0\n",
      "Episode 474 \t Total reward: 1777.0\n",
      "Episode 475 \t Total reward: 1776.0\n",
      "Episode 476 \t Total reward: 1775.0\n",
      "Episode 477 \t Total reward: 1774.0\n",
      "Episode 478 \t Total reward: 1776.0\n",
      "Episode 479 \t Total reward: 1776.0\n",
      "Episode 480 \t Total reward: 1775.0\n",
      "Episode 481 \t Total reward: 1776.0\n",
      "Episode 482 \t Total reward: 1775.0\n",
      "Episode 483 \t Total reward: 1776.0\n",
      "Episode 484 \t Total reward: 1776.0\n",
      "Episode 485 \t Total reward: 1776.0\n",
      "Episode 486 \t Total reward: 1776.0\n",
      "Episode 487 \t Total reward: 1776.0\n",
      "Episode 488 \t Total reward: 1776.0\n",
      "Episode 489 \t Total reward: 1777.0\n",
      "Episode 490 \t Total reward: 1776.0\n",
      "Episode 491 \t Total reward: 1776.0\n",
      "Episode 492 \t Total reward: 1776.0\n",
      "Episode 493 \t Total reward: 1775.0\n",
      "Episode 494 \t Total reward: 1775.0\n",
      "Episode 495 \t Total reward: 1776.0\n",
      "Episode 496 \t Total reward: 1776.0\n",
      "Episode 497 \t Total reward: 1775.0\n",
      "Episode 498 \t Total reward: 1776.0\n",
      "Episode 499 \t Total reward: 1777.0\n",
      "Episode 500 \t Total reward: 1776.0\n",
      "Episode 501 \t Total reward: 1776.0\n",
      "Episode 502 \t Total reward: 1776.0\n",
      "Episode 503 \t Total reward: 1776.0\n",
      "Episode 504 \t Total reward: 1776.0\n",
      "Episode 505 \t Total reward: 1776.0\n",
      "Episode 506 \t Total reward: 1775.0\n",
      "Episode 507 \t Total reward: 1775.0\n",
      "Episode 508 \t Total reward: 1776.0\n",
      "Episode 509 \t Total reward: 1775.0\n",
      "Episode 510 \t Total reward: 1776.0\n",
      "Episode 511 \t Total reward: 1776.0\n",
      "Episode 512 \t Total reward: 1776.0\n",
      "Episode 513 \t Total reward: 1776.0\n",
      "Episode 514 \t Total reward: 1776.0\n",
      "Episode 515 \t Total reward: 1775.0\n",
      "Episode 516 \t Total reward: 1776.0\n",
      "Episode 517 \t Total reward: 1776.0\n",
      "Episode 518 \t Total reward: 1775.0\n",
      "Episode 519 \t Total reward: 1776.0\n",
      "Episode 520 \t Total reward: 1776.0\n",
      "Episode 521 \t Total reward: 1776.0\n",
      "Episode 522 \t Total reward: 1776.0\n",
      "Episode 523 \t Total reward: 1776.0\n",
      "Episode 524 \t Total reward: 1776.0\n",
      "Episode 525 \t Total reward: 1775.0\n",
      "Episode 526 \t Total reward: 1775.0\n",
      "Episode 527 \t Total reward: 1775.0\n",
      "Episode 528 \t Total reward: 1775.0\n",
      "Episode 529 \t Total reward: 1776.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[477], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_step \u001b[38;5;241m%\u001b[39m update_timestep \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     memory\u001b[38;5;241m.\u001b[39mclear_memory()\n\u001b[0;32m     38\u001b[0m     time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[475], line 80\u001b[0m, in \u001b[0;36mPPO.update\u001b[1;34m(self, memory)\u001b[0m\n\u001b[0;32m     77\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmin(surr1, surr2) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMseLoss(state_values, rewards) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.01\u001b[39m\u001b[38;5;241m*\u001b[39mdist_entropy\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_old\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Model PPO\n",
    "env = CustomEnv()\n",
    "\n",
    "# Use the custom environment with the PPO algorithm\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "ppo = PPO(state_dim, action_dim)\n",
    "memory = Memory()\n",
    "\n",
    "max_episodes = 1800\n",
    "max_timesteps = 2000\n",
    "update_timestep = 2000\n",
    "print_freq = 1\n",
    "\n",
    "time_step = 0\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(1, max_episodes + 1):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    for t in range(max_timesteps):\n",
    "        time_step += 1\n",
    "        action, logprob = ppo.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        memory.add_state(torch.FloatTensor(state))\n",
    "        memory.add_action(torch.tensor(action))\n",
    "        memory.add_logprob(torch.tensor(logprob))\n",
    "        memory.add_reward(reward)\n",
    "        memory.add_is_terminal(done)\n",
    "        \n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo.update(memory)\n",
    "            memory.clear_memory()\n",
    "            time_step = 0\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    if episode % print_freq == 0:\n",
    "        print(\"Episode {} \\t Total reward: {}\".format(episode, episode_reward))\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 6230.7 +/- 1.1874342087037917\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model PPO\n",
    "def evaluate_policy(env, model, n_eval_episodes=1000):\n",
    "    episode_rewards = []\n",
    "    for _ in range(n_eval_episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "        episode_rewards.append(episode_reward)\n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(env, ppo, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 6231.0\n",
      "Episode: 2, Score: 6230.0\n",
      "Episode: 3, Score: 6231.0\n",
      "Episode: 4, Score: 6229.0\n",
      "Episode: 5, Score: 6231.0\n",
      "Episode: 6, Score: 6231.0\n",
      "Episode: 7, Score: 6232.0\n",
      "Episode: 8, Score: 6231.0\n",
      "Episode: 9, Score: 6230.0\n",
      "Episode: 10, Score: 6230.0\n",
      "Episode: 11, Score: 6228.0\n",
      "Episode: 12, Score: 6229.0\n",
      "Episode: 13, Score: 6231.0\n",
      "Episode: 14, Score: 6233.0\n",
      "Episode: 15, Score: 6230.0\n",
      "Episode: 16, Score: 6232.0\n",
      "Episode: 17, Score: 6232.0\n",
      "Episode: 18, Score: 6231.0\n",
      "Episode: 19, Score: 6229.0\n",
      "Episode: 20, Score: 6231.0\n",
      "Episode: 21, Score: 6230.0\n",
      "Episode: 22, Score: 6232.0\n",
      "Episode: 23, Score: 6232.0\n",
      "Episode: 24, Score: 6232.0\n",
      "Episode: 25, Score: 6231.0\n",
      "Episode: 26, Score: 6231.0\n",
      "Episode: 27, Score: 6228.0\n",
      "Episode: 28, Score: 6232.0\n",
      "Episode: 29, Score: 6231.0\n",
      "Episode: 30, Score: 6232.0\n",
      "Episode: 31, Score: 6231.0\n",
      "Episode: 32, Score: 6230.0\n",
      "Episode: 33, Score: 6229.0\n",
      "Episode: 34, Score: 6230.0\n",
      "Episode: 35, Score: 6233.0\n",
      "Episode: 36, Score: 6231.0\n",
      "Episode: 37, Score: 6231.0\n",
      "Episode: 38, Score: 6232.0\n",
      "Episode: 39, Score: 6230.0\n",
      "Episode: 40, Score: 6232.0\n",
      "Episode: 41, Score: 6230.0\n",
      "Episode: 42, Score: 6232.0\n",
      "Episode: 43, Score: 6233.0\n",
      "Episode: 44, Score: 6232.0\n",
      "Episode: 45, Score: 6231.0\n",
      "Episode: 46, Score: 6233.0\n",
      "Episode: 47, Score: 6230.0\n",
      "Episode: 48, Score: 6229.0\n",
      "Episode: 49, Score: 6231.0\n",
      "Episode: 50, Score: 6232.0\n",
      "Episode: 51, Score: 6231.0\n",
      "Episode: 52, Score: 6232.0\n",
      "Episode: 53, Score: 6232.0\n",
      "Episode: 54, Score: 6232.0\n",
      "Episode: 55, Score: 6232.0\n",
      "Episode: 56, Score: 6231.0\n",
      "Episode: 57, Score: 6229.0\n",
      "Episode: 58, Score: 6232.0\n",
      "Episode: 59, Score: 6232.0\n",
      "Episode: 60, Score: 6232.0\n",
      "Episode: 61, Score: 6231.0\n",
      "Episode: 62, Score: 6229.0\n",
      "Episode: 63, Score: 6229.0\n",
      "Episode: 64, Score: 6232.0\n",
      "Episode: 65, Score: 6230.0\n",
      "Episode: 66, Score: 6231.0\n",
      "Episode: 67, Score: 6231.0\n",
      "Episode: 68, Score: 6232.0\n",
      "Episode: 69, Score: 6230.0\n",
      "Episode: 70, Score: 6228.0\n",
      "Episode: 71, Score: 6231.0\n",
      "Episode: 72, Score: 6233.0\n",
      "Episode: 73, Score: 6230.0\n",
      "Episode: 74, Score: 6231.0\n",
      "Episode: 75, Score: 6230.0\n",
      "Episode: 76, Score: 6229.0\n",
      "Episode: 77, Score: 6230.0\n",
      "Episode: 78, Score: 6232.0\n",
      "Episode: 79, Score: 6231.0\n",
      "Episode: 80, Score: 6232.0\n",
      "Episode: 81, Score: 6232.0\n",
      "Episode: 82, Score: 6231.0\n",
      "Episode: 83, Score: 6231.0\n",
      "Episode: 84, Score: 6229.0\n",
      "Episode: 85, Score: 6232.0\n",
      "Episode: 86, Score: 6232.0\n",
      "Episode: 87, Score: 6229.0\n",
      "Episode: 88, Score: 6228.0\n",
      "Episode: 89, Score: 6230.0\n",
      "Episode: 90, Score: 6233.0\n",
      "Episode: 91, Score: 6228.0\n",
      "Episode: 92, Score: 6231.0\n",
      "Episode: 93, Score: 6231.0\n",
      "Episode: 94, Score: 6231.0\n",
      "Episode: 95, Score: 6231.0\n",
      "Episode: 96, Score: 6232.0\n",
      "Episode: 97, Score: 6230.0\n",
      "Episode: 98, Score: 6231.0\n",
      "Episode: 99, Score: 6232.0\n",
      "Episode: 100, Score: 6232.0\n",
      "Episode: 101, Score: 6229.0\n",
      "Episode: 102, Score: 6231.0\n",
      "Episode: 103, Score: 6230.0\n",
      "Episode: 104, Score: 6233.0\n",
      "Episode: 105, Score: 6231.0\n",
      "Episode: 106, Score: 6231.0\n",
      "Episode: 107, Score: 6231.0\n",
      "Episode: 108, Score: 6229.0\n",
      "Episode: 109, Score: 6230.0\n",
      "Episode: 110, Score: 6232.0\n",
      "Episode: 111, Score: 6231.0\n",
      "Episode: 112, Score: 6229.0\n",
      "Episode: 113, Score: 6231.0\n",
      "Episode: 114, Score: 6230.0\n",
      "Episode: 115, Score: 6230.0\n",
      "Episode: 116, Score: 6231.0\n",
      "Episode: 117, Score: 6230.0\n",
      "Episode: 118, Score: 6230.0\n",
      "Episode: 119, Score: 6231.0\n",
      "Episode: 120, Score: 6232.0\n",
      "Episode: 121, Score: 6230.0\n",
      "Episode: 122, Score: 6231.0\n",
      "Episode: 123, Score: 6230.0\n",
      "Episode: 124, Score: 6228.0\n",
      "Episode: 125, Score: 6230.0\n",
      "Episode: 126, Score: 6232.0\n",
      "Episode: 127, Score: 6232.0\n",
      "Episode: 128, Score: 6233.0\n",
      "Episode: 129, Score: 6230.0\n",
      "Episode: 130, Score: 6231.0\n",
      "Episode: 131, Score: 6228.0\n",
      "Episode: 132, Score: 6232.0\n",
      "Episode: 133, Score: 6230.0\n",
      "Episode: 134, Score: 6232.0\n",
      "Episode: 135, Score: 6232.0\n",
      "Episode: 136, Score: 6232.0\n",
      "Episode: 137, Score: 6230.0\n",
      "Episode: 138, Score: 6230.0\n",
      "Episode: 139, Score: 6230.0\n",
      "Episode: 140, Score: 6232.0\n",
      "Episode: 141, Score: 6229.0\n",
      "Episode: 142, Score: 6230.0\n",
      "Episode: 143, Score: 6232.0\n",
      "Episode: 144, Score: 6230.0\n",
      "Episode: 145, Score: 6232.0\n",
      "Episode: 146, Score: 6230.0\n",
      "Episode: 147, Score: 6230.0\n",
      "Episode: 148, Score: 6230.0\n",
      "Episode: 149, Score: 6231.0\n",
      "Episode: 150, Score: 6232.0\n",
      "Episode: 151, Score: 6232.0\n",
      "Episode: 152, Score: 6232.0\n",
      "Episode: 153, Score: 6232.0\n",
      "Episode: 154, Score: 6231.0\n",
      "Episode: 155, Score: 6230.0\n",
      "Episode: 156, Score: 6232.0\n",
      "Episode: 157, Score: 6232.0\n",
      "Episode: 158, Score: 6231.0\n",
      "Episode: 159, Score: 6232.0\n",
      "Episode: 160, Score: 6231.0\n",
      "Episode: 161, Score: 6232.0\n",
      "Episode: 162, Score: 6232.0\n",
      "Episode: 163, Score: 6230.0\n",
      "Episode: 164, Score: 6230.0\n",
      "Episode: 165, Score: 6232.0\n",
      "Episode: 166, Score: 6231.0\n",
      "Episode: 167, Score: 6231.0\n",
      "Episode: 168, Score: 6230.0\n",
      "Episode: 169, Score: 6233.0\n",
      "Episode: 170, Score: 6229.0\n",
      "Episode: 171, Score: 6231.0\n",
      "Episode: 172, Score: 6233.0\n",
      "Episode: 173, Score: 6231.0\n",
      "Episode: 174, Score: 6230.0\n",
      "Episode: 175, Score: 6227.0\n",
      "Episode: 176, Score: 6231.0\n",
      "Episode: 177, Score: 6232.0\n",
      "Episode: 178, Score: 6230.0\n",
      "Episode: 179, Score: 6231.0\n",
      "Episode: 180, Score: 6232.0\n",
      "Episode: 181, Score: 6231.0\n",
      "Episode: 182, Score: 6232.0\n",
      "Episode: 183, Score: 6230.0\n",
      "Episode: 184, Score: 6231.0\n",
      "Episode: 185, Score: 6232.0\n",
      "Episode: 186, Score: 6232.0\n",
      "Episode: 187, Score: 6230.0\n",
      "Episode: 188, Score: 6232.0\n",
      "Episode: 189, Score: 6231.0\n",
      "Episode: 190, Score: 6232.0\n",
      "Episode: 191, Score: 6231.0\n",
      "Episode: 192, Score: 6233.0\n",
      "Episode: 193, Score: 6230.0\n",
      "Episode: 194, Score: 6231.0\n",
      "Episode: 195, Score: 6230.0\n",
      "Episode: 196, Score: 6229.0\n",
      "Episode: 197, Score: 6231.0\n",
      "Episode: 198, Score: 6231.0\n",
      "Episode: 199, Score: 6231.0\n",
      "Episode: 200, Score: 6231.0\n",
      "Episode: 201, Score: 6234.0\n",
      "Episode: 202, Score: 6232.0\n",
      "Episode: 203, Score: 6228.0\n",
      "Episode: 204, Score: 6231.0\n",
      "Episode: 205, Score: 6229.0\n",
      "Episode: 206, Score: 6229.0\n",
      "Episode: 207, Score: 6231.0\n",
      "Episode: 208, Score: 6230.0\n",
      "Episode: 209, Score: 6231.0\n",
      "Episode: 210, Score: 6230.0\n",
      "Episode: 211, Score: 6231.0\n",
      "Episode: 212, Score: 6230.0\n",
      "Episode: 213, Score: 6232.0\n",
      "Episode: 214, Score: 6232.0\n",
      "Episode: 215, Score: 6232.0\n",
      "Episode: 216, Score: 6232.0\n",
      "Episode: 217, Score: 6233.0\n",
      "Episode: 218, Score: 6232.0\n",
      "Episode: 219, Score: 6232.0\n",
      "Episode: 220, Score: 6230.0\n",
      "Episode: 221, Score: 6231.0\n",
      "Episode: 222, Score: 6230.0\n",
      "Episode: 223, Score: 6231.0\n",
      "Episode: 224, Score: 6231.0\n",
      "Episode: 225, Score: 6231.0\n",
      "Episode: 226, Score: 6231.0\n",
      "Episode: 227, Score: 6231.0\n",
      "Episode: 228, Score: 6233.0\n",
      "Episode: 229, Score: 6232.0\n",
      "Episode: 230, Score: 6231.0\n",
      "Episode: 231, Score: 6231.0\n",
      "Episode: 232, Score: 6229.0\n",
      "Episode: 233, Score: 6231.0\n",
      "Episode: 234, Score: 6231.0\n",
      "Episode: 235, Score: 6231.0\n",
      "Episode: 236, Score: 6232.0\n",
      "Episode: 237, Score: 6231.0\n",
      "Episode: 238, Score: 6232.0\n",
      "Episode: 239, Score: 6232.0\n",
      "Episode: 240, Score: 6228.0\n",
      "Episode: 241, Score: 6231.0\n",
      "Episode: 242, Score: 6232.0\n",
      "Episode: 243, Score: 6230.0\n",
      "Episode: 244, Score: 6231.0\n",
      "Episode: 245, Score: 6230.0\n",
      "Episode: 246, Score: 6230.0\n",
      "Episode: 247, Score: 6230.0\n",
      "Episode: 248, Score: 6230.0\n",
      "Episode: 249, Score: 6233.0\n",
      "Episode: 250, Score: 6231.0\n",
      "Episode: 251, Score: 6231.0\n",
      "Episode: 252, Score: 6231.0\n",
      "Episode: 253, Score: 6229.0\n",
      "Episode: 254, Score: 6231.0\n",
      "Episode: 255, Score: 6231.0\n",
      "Episode: 256, Score: 6229.0\n",
      "Episode: 257, Score: 6232.0\n",
      "Episode: 258, Score: 6231.0\n",
      "Episode: 259, Score: 6229.0\n",
      "Episode: 260, Score: 6232.0\n",
      "Episode: 261, Score: 6231.0\n",
      "Episode: 262, Score: 6232.0\n",
      "Episode: 263, Score: 6231.0\n",
      "Episode: 264, Score: 6232.0\n",
      "Episode: 265, Score: 6232.0\n",
      "Episode: 266, Score: 6231.0\n",
      "Episode: 267, Score: 6231.0\n",
      "Episode: 268, Score: 6232.0\n",
      "Episode: 269, Score: 6231.0\n",
      "Episode: 270, Score: 6231.0\n",
      "Episode: 271, Score: 6230.0\n",
      "Episode: 272, Score: 6232.0\n",
      "Episode: 273, Score: 6232.0\n",
      "Episode: 274, Score: 6233.0\n",
      "Episode: 275, Score: 6231.0\n",
      "Episode: 276, Score: 6232.0\n",
      "Episode: 277, Score: 6232.0\n",
      "Episode: 278, Score: 6229.0\n",
      "Episode: 279, Score: 6231.0\n",
      "Episode: 280, Score: 6231.0\n",
      "Episode: 281, Score: 6231.0\n",
      "Episode: 282, Score: 6234.0\n",
      "Episode: 283, Score: 6232.0\n",
      "Episode: 284, Score: 6232.0\n",
      "Episode: 285, Score: 6232.0\n",
      "Episode: 286, Score: 6229.0\n",
      "Episode: 287, Score: 6230.0\n",
      "Episode: 288, Score: 6231.0\n",
      "Episode: 289, Score: 6231.0\n",
      "Episode: 290, Score: 6231.0\n",
      "Episode: 291, Score: 6230.0\n",
      "Episode: 292, Score: 6228.0\n",
      "Episode: 293, Score: 6230.0\n",
      "Episode: 294, Score: 6231.0\n",
      "Episode: 295, Score: 6230.0\n",
      "Episode: 296, Score: 6230.0\n",
      "Episode: 297, Score: 6230.0\n",
      "Episode: 298, Score: 6227.0\n",
      "Episode: 299, Score: 6232.0\n",
      "Episode: 300, Score: 6232.0\n",
      "Episode: 301, Score: 6232.0\n",
      "Episode: 302, Score: 6232.0\n",
      "Episode: 303, Score: 6230.0\n",
      "Episode: 304, Score: 6231.0\n",
      "Episode: 305, Score: 6230.0\n",
      "Episode: 306, Score: 6229.0\n",
      "Episode: 307, Score: 6232.0\n",
      "Episode: 308, Score: 6228.0\n",
      "Episode: 309, Score: 6232.0\n",
      "Episode: 310, Score: 6231.0\n",
      "Episode: 311, Score: 6233.0\n",
      "Episode: 312, Score: 6232.0\n",
      "Episode: 313, Score: 6231.0\n",
      "Episode: 314, Score: 6232.0\n",
      "Episode: 315, Score: 6232.0\n",
      "Episode: 316, Score: 6234.0\n",
      "Episode: 317, Score: 6231.0\n",
      "Episode: 318, Score: 6230.0\n",
      "Episode: 319, Score: 6229.0\n",
      "Episode: 320, Score: 6228.0\n",
      "Episode: 321, Score: 6231.0\n",
      "Episode: 322, Score: 6229.0\n",
      "Episode: 323, Score: 6228.0\n",
      "Episode: 324, Score: 6228.0\n",
      "Episode: 325, Score: 6230.0\n",
      "Episode: 326, Score: 6231.0\n",
      "Episode: 327, Score: 6231.0\n",
      "Episode: 328, Score: 6232.0\n",
      "Episode: 329, Score: 6228.0\n",
      "Episode: 330, Score: 6232.0\n",
      "Episode: 331, Score: 6229.0\n",
      "Episode: 332, Score: 6230.0\n",
      "Episode: 333, Score: 6232.0\n",
      "Episode: 334, Score: 6232.0\n",
      "Episode: 335, Score: 6227.0\n",
      "Episode: 336, Score: 6231.0\n",
      "Episode: 337, Score: 6230.0\n",
      "Episode: 338, Score: 6230.0\n",
      "Episode: 339, Score: 6230.0\n",
      "Episode: 340, Score: 6231.0\n",
      "Episode: 341, Score: 6231.0\n",
      "Episode: 342, Score: 6232.0\n",
      "Episode: 343, Score: 6232.0\n",
      "Episode: 344, Score: 6231.0\n",
      "Episode: 345, Score: 6231.0\n",
      "Episode: 346, Score: 6230.0\n",
      "Episode: 347, Score: 6232.0\n",
      "Episode: 348, Score: 6229.0\n",
      "Episode: 349, Score: 6231.0\n",
      "Episode: 350, Score: 6230.0\n",
      "Episode: 351, Score: 6232.0\n",
      "Episode: 352, Score: 6230.0\n",
      "Episode: 353, Score: 6231.0\n",
      "Episode: 354, Score: 6230.0\n",
      "Episode: 355, Score: 6231.0\n",
      "Episode: 356, Score: 6230.0\n",
      "Episode: 357, Score: 6229.0\n",
      "Episode: 358, Score: 6232.0\n",
      "Episode: 359, Score: 6229.0\n",
      "Episode: 360, Score: 6232.0\n",
      "Episode: 361, Score: 6232.0\n",
      "Episode: 362, Score: 6229.0\n",
      "Episode: 363, Score: 6232.0\n",
      "Episode: 364, Score: 6230.0\n",
      "Episode: 365, Score: 6231.0\n",
      "Episode: 366, Score: 6230.0\n",
      "Episode: 367, Score: 6232.0\n",
      "Episode: 368, Score: 6232.0\n",
      "Episode: 369, Score: 6229.0\n",
      "Episode: 370, Score: 6231.0\n",
      "Episode: 371, Score: 6232.0\n",
      "Episode: 372, Score: 6231.0\n",
      "Episode: 373, Score: 6232.0\n",
      "Episode: 374, Score: 6229.0\n",
      "Episode: 375, Score: 6228.0\n",
      "Episode: 376, Score: 6230.0\n",
      "Episode: 377, Score: 6232.0\n",
      "Episode: 378, Score: 6231.0\n",
      "Episode: 379, Score: 6233.0\n",
      "Episode: 380, Score: 6231.0\n",
      "Episode: 381, Score: 6232.0\n",
      "Episode: 382, Score: 6231.0\n",
      "Episode: 383, Score: 6232.0\n",
      "Episode: 384, Score: 6232.0\n",
      "Episode: 385, Score: 6232.0\n",
      "Episode: 386, Score: 6231.0\n",
      "Episode: 387, Score: 6233.0\n",
      "Episode: 388, Score: 6231.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[479], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m----> 9\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     11\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[475], line 26\u001b[0m, in \u001b[0;36mPPO.select_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m---> 26\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_old(state), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Categorical(action_probs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Visualisasi hasil training\n",
    "episodes = len(dataset['Status'])\n",
    "scores = []\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action, _ = ppo.select_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    scores.append(score)\n",
    "    print(f\"Episode: {episode}, Score: {score}\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Plotting the scores\n",
    "plt.plot(range(len(scores)), scores)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Training Performance Over Time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cpu_usage  memory_usage  bandwidth_inbound  bandwidth_outbound  tps  \\\n",
      "0      0.090         0.535               7.46                6.45  2.0   \n",
      "1      0.166         0.533               5.85                5.27  2.2   \n",
      "2      0.202         0.553               9.06                7.96  3.2   \n",
      "3      0.146         0.580               8.41                7.21  3.2   \n",
      "4      0.102         0.535               4.88                4.30  2.6   \n",
      "\n",
      "   tps_error  response_time  Status  \n",
      "0        0.0          0.607       0  \n",
      "1        0.0          2.090       0  \n",
      "2        0.0          3.450       0  \n",
      "3        0.0          2.580       0  \n",
      "4        0.0          0.862       0  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[480], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m episode_rewards, predicted_statuses\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Evaluasi dan dapatkan predicted status\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m mean_reward, std_reward \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1438\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m _, predicted_statuses \u001b[38;5;241m=\u001b[39m evaluate_and_compare(env, ppo, n_eval_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1800\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Comparison\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[478], line 9\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(env, model, n_eval_episodes)\u001b[0m\n\u001b[0;32m      7\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m----> 9\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     11\u001b[0m     episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[475], line 26\u001b[0m, in \u001b[0;36mPPO.select_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m---> 26\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m     action_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_old(state), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Categorical(action_probs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load actual data for comparison\n",
    "actual_data = dataset\n",
    "print(actual_data.head())\n",
    "\n",
    "predicted_statuses = []\n",
    "actual_statuses = actual_data['Status'].tolist()\n",
    "\n",
    "def evaluate_and_compare(env, model, n_eval_episodes=10):\n",
    "    episode_rewards = []\n",
    "    predicted_statuses = []\n",
    "    for episode in range(n_eval_episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.select_action(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            if done:\n",
    "                predicted_statuses.append(episode_reward)  # Example status: total reward dari episode\n",
    "        episode_rewards.append(episode_reward)\n",
    "    return episode_rewards, predicted_statuses\n",
    "\n",
    "# Evaluasi dan dapatkan predicted status\n",
    "mean_reward, std_reward = evaluate_policy(env, ppo, n_eval_episodes=1438)\n",
    "_, predicted_statuses = evaluate_and_compare(env, ppo, n_eval_episodes=1800)\n",
    "\n",
    "# Comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Status': actual_statuses[:len(predicted_statuses)],  # Ensure matching length\n",
    "    'Predicted Status': predicted_statuses\n",
    "})\n",
    "\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualization\n",
    "comparison_df.plot(kind='bar', figsize=(10, 5))\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Status')\n",
    "plt.title('Comparison of Actual and Predicted Status')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Validation Data\n",
      "[[   0 1228]\n",
      " [   0  210]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Validation Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Menghitung dan menampilkan confusion matrix untuk data validasi\n",
    "cm_val = confusion_matrix(y_test, predicted_statuses)\n",
    "print(\"Confusion Matrix - Validation Data\")\n",
    "print(cm_val)\n",
    "\n",
    "# Menampilkan confusion matrix sebagai heatmap untuk data validasi\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Validation Data')\n",
    "plt.show()\n",
    "\n",
    "# Menghitung dan menampilkan classification report untuk data validasi\n",
    "print(\"Classification Report - Validation Data\")\n",
    "report_val = classification_report(y_test, predicted_statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
